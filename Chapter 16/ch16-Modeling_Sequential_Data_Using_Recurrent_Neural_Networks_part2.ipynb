{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eacadc5",
   "metadata": {},
   "source": [
    "## Project two: character-level language modeling in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b674d",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72111913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1143k  100 1143k    0     0   124k      0  0:00:09  0:00:09 --:--:--  193k\n"
     ]
    }
   ],
   "source": [
    "! curl -O https://www.gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349d829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and preprocessing text\n",
    "with open('1268-0.txt', 'r') as fp:\n",
    "    text = fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16715400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1130711,)\n",
      "THE MYSTERIOUS  == Encoding ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[48 36 33  1 41 53 47 48 33 46 37 43 49 47  1] == Reverse ==> THE MYSTERIOUS \n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "print('Text encoded shape:', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(text_encoded[:15], '== Reverse ==>', ''.join(char_array[text_encoded[:15]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e401c6",
   "metadata": {},
   "source": [
    "Now, we will create a TensorFlow dataset from this array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bf653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 17:30:26.634104: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-18 17:30:26.673864: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-18 17:30:26.674466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 17:30:27.501169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 -> T\n",
      "36 -> H\n",
      "33 -> E\n",
      "1 ->  \n",
      "41 -> M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 17:30:28.532374: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbded35",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = 41\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327df36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function for splitting x & y\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9093b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "\n",
      " Input (x): 'OUS ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPAR'\n",
      "Target (y): 'US ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPART'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## inspection:\n",
    "for example in ds_sequences.take(2):\n",
    "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c331b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 40), dtype=tf.int32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05ee25",
   "metadata": {},
   "source": [
    "### Building a character-level RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4060d128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 256)         21760     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 85)          43605     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1640277 (6.26 MB)\n",
      "Trainable params: 1640277 (6.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "## Setting the training parameters\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59519012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "431/431 [==============================] - 158s 361ms/step - loss: 2.3474\n",
      "Epoch 2/10\n",
      "431/431 [==============================] - 158s 364ms/step - loss: 1.7612\n",
      "Epoch 3/10\n",
      "431/431 [==============================] - 157s 363ms/step - loss: 1.5547\n",
      "Epoch 4/10\n",
      "431/431 [==============================] - 158s 365ms/step - loss: 1.4364\n",
      "Epoch 5/10\n",
      "431/431 [==============================] - 158s 364ms/step - loss: 1.3614\n",
      "Epoch 6/10\n",
      "431/431 [==============================] - 157s 363ms/step - loss: 1.3093\n",
      "Epoch 7/10\n",
      "431/431 [==============================] - 160s 370ms/step - loss: 1.2694\n",
      "Epoch 8/10\n",
      "431/431 [==============================] - 161s 371ms/step - loss: 1.2380\n",
      "Epoch 9/10\n",
      "431/431 [==============================] - 161s 371ms/step - loss: 1.2118\n",
      "Epoch 10/10\n",
      "431/431 [==============================] - 161s 372ms/step - loss: 1.1890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7faf74479dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ))\n",
    "\n",
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c93b2",
   "metadata": {},
   "source": [
    "### Evaluation phase: generating new text passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2909547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fa590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.10650698 0.10650698 0.78698605]\n",
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b0568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island mastering a sign of rof.”\n",
      "\n",
      "“Perhaps an east coast of them it?” exclaimed Pencroft. “Eane was no fire, and therefore, my did not far.”\n",
      "\n",
      "The affarming. from\n",
      "some channel would ever a long substance, and producing a\n",
      "hearth were about the house. There the simple light of man.\n",
      "\n",
      "“Vollow Harding,” said Pencroft, a few might\n",
      "be\n",
      "procement by the wowern\n",
      "spoke of the stirnary, threatened so, ovem the right bank of the submited lava, now which commediately fall and their iron-containst of\n",
      "which Neb\n",
      "resport\n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx],\n",
    "            axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98afb1",
   "metadata": {},
   "source": [
    "* **Predictability vs. randomness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d42ac979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698604]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611688]\n",
      "Probabilities after scaling with 0.1: [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', tf.math.softmax(0.5*logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', tf.math.softmax(0.1*logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a796dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island of the common here and done of the castaways should be sufficient to continue that the corral, and the reporter was properly enough to discover the whole of the convicts, everything was such an entered the shore and the sea, and soon as the side of the lake, it was only seen that the engineer in the border of the birds had been able to stow that the pirates were therefore continued to an hour to be done but to force the engineer, and he had been able to say, the convicts were at the constructio\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e015b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island forgofach Easmatef irricsion? kitted\n",
      "ir.\n",
      "Of Juage!” -asks hisherintie?s. Tabren Neme,\n",
      "fiisaneer,\n",
      "is, bark, upon,’-smoke, rauniceablys. E5d 5 Yasly! thus?\n",
      "\n",
      "Mlercal, jamary?” ertric/Chree, “Monerforr,”\n",
      "retlees; und all,-faving a quartermasomits.\n",
      "Cyrus Harding coulded-meg, makloy! coh diffftings, butnef rod, HU. SBecUik\n",
      "51 chrestor :\n",
      "basanown” prLpool\n",
      "Flanquplusawortment,”\n",
      "\n",
      "replight. SyB)\n",
      "haledders Gideon Spiletu, whindelygithfuls, aboth me,’mucovid, ab)eretcmetting inquilists. A yindo,\n",
      "if\n",
      "thly. H\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b7514",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
