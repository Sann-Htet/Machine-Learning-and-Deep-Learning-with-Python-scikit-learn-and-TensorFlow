{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da5b3cd",
   "metadata": {},
   "source": [
    "##  The building blocks of convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5eaff9",
   "metadata": {},
   "source": [
    "### Determining the size of the convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f60951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n",
      "Numpy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv1d(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([zero_pad, x_padded, zero_pad])\n",
    "        \n",
    "    res = []\n",
    "    for i in range(0, int(len(x)/s), s):\n",
    "        res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
    "        \n",
    "    return np.array(res)\n",
    "\n",
    "## Testing:\n",
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Conv1d Implementation:',\n",
    "      conv1d(x, w, p=2, s=1))\n",
    "\n",
    "print('Numpy Results:',\n",
    "      np.convolve(x, w, mode='same')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5967f04",
   "metadata": {},
   "source": [
    "### Performing a discrete convolution in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347a1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n",
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1, ::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2 * p[0]\n",
    "    n2 = X_orig.shape[1] + 2 * p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0] + X_orig.shape[0],\n",
    "             p[1]:p[1] + X_orig.shape[1]] = X_orig\n",
    "    \n",
    "    res = []\n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0])/s[0])+1, s[0]):\n",
    "        res.append([])\n",
    "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1])/s[1])+1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0],\n",
    "                             j:j+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    \n",
    "    return (np.array(res))\n",
    "\n",
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "\n",
    "print('Conv2d Implementation:\\n',\n",
    "    conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
    "\n",
    "\n",
    "print('SciPy Results:\\n',\n",
    "    scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad5c92",
   "metadata": {},
   "source": [
    "## Putting everything together â€“ implementing a CNN\n",
    "\n",
    "### Working with multiple input or color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b13d59",
   "metadata": {},
   "source": [
    "**TIP: Reading an image file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173f1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 18:37:22.212960: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 18:37:22.293449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 18:37:22.294949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 18:37:24.105523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (252, 221, 3)\n",
      "Number of channels: 3\n",
      "Image data type: <dtype: 'uint8'>\n",
      "tf.Tensor(\n",
      "[[[179 134 110]\n",
      "  [182 136 112]]\n",
      "\n",
      " [[180 135 111]\n",
      "  [182 137 113]]], shape=(2, 2, 3), dtype=uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 18:37:25.950638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "img_raw = tf.io.read_file('example-image.png')\n",
    "img = tf.image.decode_image(img_raw)\n",
    "print('Image shape:', img.shape)\n",
    "print('Number of channels:', img.shape[2])\n",
    "print('Image data type:', img.dtype)\n",
    "print(img[100:102, 100:102, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b15820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (252, 221, 3)\n",
      "Number of channels: 3\n",
      "Image data type: uint8\n",
      "[[[179 134 110]\n",
      "  [182 136 112]]\n",
      "\n",
      " [[180 135 111]\n",
      "  [182 137 113]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43309/3047262961.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread('example-image.png')\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "\n",
    "img = imageio.imread('example-image.png')\n",
    "print('Image shape:', img.shape)\n",
    "print('Number of channels:', img.shape[2])\n",
    "print('Image data type:', img.dtype)\n",
    "print(img[100:102, 100:102, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8decb",
   "metadata": {},
   "source": [
    "## Regularizing a neural network with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beda37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "conv_layer = keras.layers.Conv2D(\n",
    "    filters=16, kernel_size=(3, 3),\n",
    "    kernel_regularizer=keras.regularizers.l2(0.001))\n",
    "\n",
    "fc_layer = keras.layers.Dense(\n",
    "    units=16, kernel_regularizer=keras.regularizers.l2(0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dd72e",
   "metadata": {},
   "source": [
    "## Loss Functions for Classification\n",
    "\n",
    " * **`BinaryCrossentropy()`**\n",
    "   * `from_logits=False` \n",
    "   * `from_logits=True`\n",
    "\n",
    " * **`CategoricalCrossentropy()`**\n",
    "   * `from_logits=False`\n",
    "   * `from_logits=True`\n",
    "   \n",
    " * **`SparseCategoricalCrossentropy()`**\n",
    "   * `from_logits=False`\n",
    "   * `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f901b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE (w Probas): 0.3711 (w Logits): 0.3711\n",
      "CCE (w Probas): 0.5996 (w Logits): 0.5996\n",
      "Sparse CCE (w Probas): 0.5996 (w Logits): 0.5996\n"
     ]
    }
   ],
   "source": [
    "####### Binary Crossentropy\n",
    "bce_probas = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "bce_logits = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "logits = tf.constant([0.8])\n",
    "probas = tf.keras.activations.sigmoid(logits)\n",
    "\n",
    "tf.print(\n",
    "    'CCE (w Probas): {:.4f}'.format(\n",
    "    bce_probas(y_true=[1], y_pred=probas)),\n",
    "    '(w Logits): {:.4f}'.format(\n",
    "    bce_logits(y_true=[1], y_pred=logits)))\n",
    "\n",
    "####### Categorical Crossentropy\n",
    "cce_probas = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False)\n",
    "cce_logits = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True)\n",
    "\n",
    "logits = tf.constant([[1.5, 0.8, 2.1]])\n",
    "probas = tf.keras.activations.softmax(logits)\n",
    "\n",
    "tf.print(\n",
    "    'CCE (w Probas): {:.4f}'.format(\n",
    "    cce_probas(y_true=[[0, 0, 1]], y_pred=probas)),\n",
    "    '(w Logits): {:.4f}'.format(\n",
    "    cce_logits(y_true=[[0, 0, 1]], y_pred=logits)))\n",
    "\n",
    "####### Sparse Categorical Crossentropy\n",
    "sp_cce_probas = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False)\n",
    "sp_cce_logits = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True)\n",
    "\n",
    "tf.print(\n",
    "    'Sparse CCE (w Probas): {:.4f}'.format(\n",
    "    sp_cce_probas(y_true=[2], y_pred=probas)),\n",
    "    '(w Logits): {:.4f}'.format(\n",
    "    sp_cce_logits(y_true=[2], y_pred=logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51580a",
   "metadata": {},
   "source": [
    "## Implementing a deep convolutional neural network using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0545010",
   "metadata": {},
   "source": [
    "### Loading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9328176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "## Loading the data\n",
    "mnist_bldr = tfds.load('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3a3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = mnist_bldr\n",
    "mnist_train_orig = datasets['train']\n",
    "mnist_test_orig = datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300eb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "mnist_train = mnist_train_orig.map(\n",
    "                lambda item: (tf.cast(item['image'], tf.float32)/255.0,\n",
    "                              tf.cast(item['label'], tf.int32)))\n",
    "\n",
    "mnist_test = mnist_test_orig.map(\n",
    "                lambda item: (tf.cast(item['image'], tf.float32)/255.0,\n",
    "                              tf.cast(item['label'], tf.int32)))\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "mnist_train = mnist_train.shuffle(buffer_size=BUFFER_SIZE,\n",
    "                                  reshuffle_each_iteration=False)\n",
    "\n",
    "mnist_valid = mnist_train.take(10000).batch(BATCH_SIZE)\n",
    "mnist_train = mnist_train.skip(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9732e33",
   "metadata": {},
   "source": [
    "### Implementing a CNN using the TensorFlow Keras API\n",
    "\n",
    "#### Configuring CNN layers in Keras\n",
    "\n",
    " * **Conv2D:** `tf.keras.layers.Conv2D`\n",
    "   * `filters`\n",
    "   * `kernel_size`\n",
    "   * `strides`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **MaxPool2D:** `tf.keras.layers.MaxPool2D`\n",
    "   * `pool_size`\n",
    "   * `strides`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **Dropout** `tf.keras.layers.Dropout2D`\n",
    "   * `rate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed57183",
   "metadata": {},
   "source": [
    "### Constructing a CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9fe36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
